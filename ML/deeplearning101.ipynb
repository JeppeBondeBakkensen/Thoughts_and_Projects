{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d19c5d7",
   "metadata": {},
   "source": [
    "## IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a771e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Import statements\n",
    "# -----------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms \n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c680cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3dcd4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, loss, optimizer, loader, epochs, verbose=True, device=device): \n",
    "    \"\"\"\n",
    "    Run training of a model given a loss function, optimizer and a set of training and validation data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Train \n",
    "    for epoch in range(epochs): \n",
    "        for times, data in enumerate(loader): \n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Zero the parameter gradients \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward and backward + optimize \n",
    "            outputs = model(inputs)\n",
    "            loss_tensor = loss(outputs, labels)\n",
    "            loss_tensor.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print statistics \n",
    "            if verbose and (times % 100 == 99):\n",
    "                print('[%d/%d, %d/%d] loss: %.3f' %\n",
    "                    (epoch+1, epochs, times+1, len(loader),\n",
    "                    loss_tensor.item()))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8ba0e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, device=device): \n",
    "    \"\"\"\n",
    "    Evaluate a model 'model' on all batches of a torch DataLoader 'data_loader'.\n",
    "\n",
    "    Returns: the total number of correct classifications,\n",
    "             the total number of images\n",
    "             the list of the per class correct classification,\n",
    "             the list of the per class total number of images.\n",
    "    \"\"\"\n",
    "    \n",
    "    # test\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            # For each sample pick the class with largest score across the class dimension (dim=1)\n",
    "            # Predicted has the shape of [batch_size] and contains class indices (e.g 0-9)\n",
    "            _, predicted = torch.max(outputs.data, dim = 1)\n",
    "            total += labels.size(0)     # tensor(57, device='cuda:0') \n",
    "            correct += (predicted == labels).sum().item()   # The .item make 57 to an int\n",
    "            \n",
    "    class_correct = [0 for i in range(10)]\n",
    "    class_total = [0 for i in range(10)]\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for data in loader: \n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, dim = 1)\n",
    "            # squeeze removes the dim = 1 so it becomes a boolean \n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    return (correct, total, class_correct, class_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "711d4476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def get_train_transforms():\n",
    "    \"\"\"Return a normalized version of the trainingset\"\"\"\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=(0.4914, 0.4822, 0.4465),\n",
    "                std=(0.2470, 0.2435, 0.2616),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_test_transforms():\n",
    "    \"\"\"Return a normalized version of testset\"\"\"\n",
    "    return transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=(0.4914, 0.4822, 0.4465),\n",
    "                std=(0.2470, 0.2435, 0.2616),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "train_ds = datasets.CIFAR10(\n",
    "        root=\"data\", train=True, download=True, transform=get_train_transforms())\n",
    "test_ds = datasets.CIFAR10(\n",
    "        root=\"data\", train=False, download=True, transform=get_test_transforms())\n",
    "train_loader = DataLoader(dataset=train_ds, batch_size=64, shuffle=True, num_workers=0,)\n",
    "test_loader = DataLoader(dataset=test_ds, batch_size=64, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb76d74",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5162697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, (3,3), (1,1), (1, 1))\n",
    "        self.conv2 = nn.Conv2d(16, 32, (3,3), (1,1), (1, 1))\n",
    "        self.fc1 = nn.Linear(32*8*8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.conv1(x)                                         # (N, 16, 32, 32)\n",
    "        x = F.relu(x)                                       # (N, 16, 32, 32)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)        # (N, 16, 16, 16)\n",
    "        x = self.conv2(x)                                         # (N, 32, 16, 16)\n",
    "        x = F.relu(x)                                       # (N, 32, 16, 16)\n",
    "        x = F.max_pool2d(x, kernel_size= 2, stride = 2)     # (N, 32, 8, 8)\n",
    "        x = torch.flatten(x, start_dim=1)                   # (N, 2048)\n",
    "        x = self.fc1(x)                                           # (N, 256)\n",
    "        x = F.relu(x)                                       # (N, 256)\n",
    "        x = self.fc2(x)                                           # (N, 10)\n",
    "        return x                                                  # logits\n",
    "\n",
    "# Make the model \n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92d11bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 50000 images\n",
      "[1/4, 100/782] loss: 1.047\n",
      "[1/4, 200/782] loss: 1.090\n",
      "[1/4, 300/782] loss: 0.842\n",
      "[1/4, 400/782] loss: 1.124\n",
      "[1/4, 500/782] loss: 1.233\n",
      "[1/4, 600/782] loss: 1.143\n",
      "[1/4, 700/782] loss: 1.120\n",
      "[2/4, 100/782] loss: 0.871\n",
      "[2/4, 200/782] loss: 1.001\n",
      "[2/4, 300/782] loss: 0.906\n",
      "[2/4, 400/782] loss: 1.111\n",
      "[2/4, 500/782] loss: 1.026\n",
      "[2/4, 600/782] loss: 1.157\n",
      "[2/4, 700/782] loss: 0.958\n",
      "[3/4, 100/782] loss: 0.986\n",
      "[3/4, 200/782] loss: 1.086\n",
      "[3/4, 300/782] loss: 0.754\n",
      "[3/4, 400/782] loss: 0.969\n",
      "[3/4, 500/782] loss: 0.760\n",
      "[3/4, 600/782] loss: 1.198\n",
      "[3/4, 700/782] loss: 0.820\n",
      "[4/4, 100/782] loss: 0.878\n",
      "[4/4, 200/782] loss: 0.924\n",
      "[4/4, 300/782] loss: 1.059\n",
      "[4/4, 400/782] loss: 1.018\n",
      "[4/4, 500/782] loss: 0.969\n",
      "[4/4, 600/782] loss: 0.852\n",
      "[4/4, 700/782] loss: 0.986\n",
      "Training Finished.\n",
      "\n",
      "Accuracy of the network on the 10000 test images: 69 %\n",
      "Accuracy of 0: 0.796000\n",
      "Accuracy of 1: 0.830000\n",
      "Accuracy of 2: 0.611000\n",
      "Accuracy of 3: 0.429000\n",
      "Accuracy of 4: 0.537000\n",
      "Accuracy of 5: 0.725000\n",
      "Accuracy of 6: 0.745000\n",
      "Accuracy of 7: 0.703000\n",
      "Accuracy of 8: 0.783000\n",
      "Accuracy of 9: 0.768000\n"
     ]
    }
   ],
   "source": [
    "# Parameters \n",
    "epochs = 4\n",
    "lr = 2e-3\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.002, momentum=0.9)\n",
    "\n",
    "# Train\n",
    "print('Training on %d images' % train_ds.data.shape[0])\n",
    "training_loop(net, loss, optimizer, train_loader, epochs)\n",
    "print('Training Finished.\\n')\n",
    "\n",
    "# Test\n",
    "correct, total, class_correct, class_total = evaluate_model(net, test_loader)\n",
    "print('Accuracy of the network on the %d test images: %d %%' % (test_ds.data.shape[0], (100*correct / total)))\n",
    "for i in range(10):\n",
    "    print('Accuracy of %d: %3f' % (i, (class_correct[i]/class_total[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60a5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
